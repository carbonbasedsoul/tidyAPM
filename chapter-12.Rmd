# Discriminant Analysis and Other Linear Classification Models

```{r chapter-12-startup, include = FALSE}
knitr::opts_chunk$set(fig.path = "figures/")
library(MASS)
library(mixOmics)
library(plsmod)
library(glmnet)
library(tidymodels)
library(workflowsets)
library(discrim)

caching <- TRUE

cores <- parallel::detectCores()
if (!grepl("mingw32", R.Version()$platform)) {
 library(doMC)
 registerDoMC(cores = cores)
} else {
  library(doParallel)
  cl <- makePSOCKcluster(cores)
  registerDoParallel(cl)
}

source("extras/overlay_roc_curves.R")
```


The R packages used in this chapter are: `r pkg_text(c("tidymodels", "MASS", "discrim", "glmnet",
"mixOmics", "plsmod"))`. 


mention mix of workflow sets and workflows

## Case Study: Predicting Successful Grant Applications

These data are supplied in the GitHub repository. The object `grants_testing` holds the test set while `grants_other` contains the data used for modeling and initial evaluation. 

We recreated the same split used in _APM_ here. However, the nature of this data splitting scheme is fairly irregular. For this reason, a non-standard `r pkg(rsample)` method was used; the results are the same as those produced by a more standard application of `initial_split()`. The code to create the `grants_split` object is found in [`extras/grants_splits.R`](https://github.com/topepo/tidyAPM/tree/main/extras/grants_splits.R).   

```{r chapter-12-data}
library(tidymodels)
data(grants)

ls(pattern = "grants")

load("RData/grants_split.RData")

grants_split
nrow(grants_test)
```
`grants_split` is a validation-type resampling object. As noted in _APM_, $n = `r nrow(analysis(grants_split$splits[[1]]))`$ grants is use for model fitting while we predict $n = `r nrow(assessment(grants_split$splits[[1]]))`$ grants to measure model performance. We create the final model using both of these data sets. The final test set contains $n = `r nrow(grants_test)`$ grants are used as the final test set assessment.  

## Logistic Regression

An initial simple logistic regression model is fit to the data. Two  recipes removes zero variance predictors and near-zero predictors, respectively. In these recipes, the indicator variables for the factor predictors are created prior to these filters. The opposite order could have been used and it would likely to yield somewhat different results.  Unlike `r pkg(caret)`, where the preprocessing order is fixed, the recipe gives the user more options. This is a feature but illustrates that the order of operations may not be obvious. 

Since there are no tuning parameters, both recipes are simply resampled. A workflow set is used: 

```{r chapter-12-logistic, cache = caching}
library(workflowsets)

rs_ctrl <- control_resamples(save_pred = TRUE, save_workflow = TRUE, 
                             parallel_over = "everything")

zv_rec <- 
 recipe(class ~ ., data = grants_other) %>% 
 step_dummy(all_nominal_predictors()) %>% 
 step_zv(all_predictors())

nzv_rec <- 
 recipe(class ~ ., data = grants_other) %>% 
 step_dummy(all_nominal_predictors()) %>% 
 step_nzv(all_predictors())

logistic_spec <-
 logistic_reg() %>% 
 set_engine("glm")

logistic_wflow_set <- 
 workflow_set(
  preproc = list(none = zv_rec, nzv = nzv_rec),
  models =  list(logistic = logistic_spec),
  cross = TRUE
 ) %>% 
 workflow_map(fn = "fit_resamples", resamples = grants_split, seed = 1201,
              control = rs_ctrl)
```


```{r chapter-12-glm-res}
collect_metrics(logistic_wflow_set) %>% 
  select(wflow_id, .metric, mean, n, std_err) %>% 
  arrange(.metric)
```

The results show that using all of the predictors in the model has a significant negative effect on the model. Note that there are no standard errors associated with the results. This is a consequence of the validation set being a single resample. 

A function called `overlay_roc_curves()` can be used to emulate the ROC curve figures shown in _APM_. The implementation is not complex and the code is found in the [`extras`](https://github.com/topepo/tidyAPM/blob/main/extras/overlay_roc_curves.R) directory. The inputs are a data frame of holdout predictors and a character string for the workflow ID that should be highlighted. All other curves are shown in a transparent grey color.  

```{r chapter-12-fig-04}
model_predictions <- collect_predictions(logistic_wflow_set) 

overlay_roc_curves(model_predictions, highlight = "nzv_logistic") 
```

## Linear Discriminant Analysis

A similar strategy is used for linear discriminant analysis. The `discrim` package has a set of discriminant models; we will use `discrim_linear()` to access the `lda()` function in the `r pkg(MASS)` package: 

```{r chapter-12-lda, cache = caching}
library(discrim)

lda_spec <-
 discrim_linear() %>% 
 set_engine("MASS")

lda_wflow_set <- 
 workflow_set(
  preproc = list(none = zv_rec, nzv = nzv_rec),
  models =  list(LDA = lda_spec),
  cross = TRUE
 ) %>% 
 workflow_map(fn = "fit_resamples", resamples = grants_split, seed = 1201,
              control = rs_ctrl)
 
collect_metrics(lda_wflow_set) %>% 
  select(wflow_id, .metric, mean, n, std_err) %>% 
  arrange(.metric)
```

We then highlight the better of the two LDA models. Again, the near-zero variance filter has a positive effect on the results.  

```{r chapter-12-fig-09}
model_predictions <- 
 collect_predictions(lda_wflow_set)  %>% 
 bind_rows(model_predictions)

overlay_roc_curves(model_predictions, highlight = "nzv_LDA") 
```

## Partial Least Squares Discriminant Analysis

Similarly, the `r pkg(plsmod)` package contains the model definitions for the PLS discriminant analysis. Here, the number of PLS components is tuned. 

```{r chapter-12-pls, cache = caching}
library(plsmod)

pls_spec <-
 pls(num_comp = tune()) %>% 
 set_mode("classification") %>% 
 set_engine("mixOmics")

gd_ctrl <- control_grid(save_pred = TRUE, save_workflow = TRUE, 
                        parallel_over = "everything")

pls_wflow_set <- 
 workflow_set(
  preproc = list(none = zv_rec, nzv = nzv_rec),
  models =  list(PLS = pls_spec),
  cross = TRUE
 ) %>% 
 workflow_map(resamples = grants_split, seed = 1201, grid = tibble(num_comp = 1:10),
              control = gd_ctrl)
 
```

To overlay the effect of the two filters, we extra the metrics, stack them, then a basic `r pkg(ggplot2)` plot is created: 

```{r chapter-12-fig-12}
pls_wflow_set %>% 
 mutate(metrics = map(result, collect_metrics)) %>% 
 select(wflow_id, metrics) %>% 
 unnest(cols = metrics) %>% 
 filter(.metric == "roc_auc") %>% 
 ggplot(aes(x = num_comp, y = mean, col = wflow_id)) + 
 geom_point() + 
 geom_line() + 
 labs(x = "Number of PLS Components", y = "roc_auc")
```

The better variant of the model is once again the more heavily filtered recipe: 

```{r chapter-12-fig-13}
model_predictions <- 
 collect_predictions(pls_wflow_set, select_best = TRUE, metric = "roc_auc")  %>% 
 bind_rows(model_predictions)

overlay_roc_curves(model_predictions, highlight = "nzv_PLS") 
```


## Penalized Models

As before, the `glmnet` model is the focus for penalized models. The penalty and mixture parameters are optimized using a pre-defined grid. Since this model does feature selection, it is coupled with the more lightly filtered recipe. 

```{r chapter-12-glmnet, cache = caching}
glmnet_spec <-
 logistic_reg(penalty = tune(), mixture = tune()) %>% 
 set_mode("classification") %>% 
 set_engine("glmnet")

glmn_grid <-
        tidyr::crossing(
          penalty = 10 ^ seq(-3, 0, length.out = 20),
          mixture = c(0.05, .2, .4, .6, .8, 1)
        )

glmnet_wflow <- 
 workflow() %>% 
 add_model(glmnet_spec) %>% 
 add_recipe(zv_rec)

set.seed(1201)
glmnet_tune <- 
 glmnet_wflow %>% 
 tune_grid(resamples = grants_split, grid = glmn_grid,
              control = gd_ctrl)
```

The results show that there are multiple penalties that have about the same performance (for different mixtures of penalty types). For a few settings, the amount of penalization removes all of the predictors thereby producing an area under the curve of 0.50.  

```{r chapter-12-fig-16a}
autoplot(glmnet_tune, metric = "roc_auc")
```

For some probability threshold, this model has the best results so far. 

```{r chapter-12-fig-16b}
model_predictions <- 
  as_workflow_set(none_glmnet = glmnet_tune) %>% 
  collect_predictions(select_best = TRUE, metric = "roc_auc") %>% 
  bind_rows(model_predictions)

overlay_roc_curves(model_predictions, highlight = "none_glmnet") 
```

## Nearest Shrunken Centroids

This particular model has not been enabled in the tidymodels packages to date. 


```{r chapter-12-teardown, include = FALSE}
if (grepl("mingw32", R.Version()$platform)) {
 stopCluster(cl)
} 

save(logistic_wflow_set, lda_wflow_set, pls_wflow_set, glmnet_tune,
     version = 2, compress = "xz", file = "RData/chapter_12.RData")
```


