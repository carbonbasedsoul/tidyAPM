# Case Study: Compressive Strength of Concrete Mixtures

```{r chapter-10-startup, include = FALSE}
knitr::opts_chunk$set(fig.path = "figures/")
library(tidymodels)
library(tbd)
library(baguette)
library(rules)
library(janitor)
library(finetune)

caching <- TRUE

cores <- parallel::detectCores()
if (!grepl("mingw32", R.Version()$platform)) {
 library(doMC)
 registerDoMC(cores = cores)
} else {
  library(doParallel)
  cl <- makePSOCKcluster(cores)
  registerDoParallel(cl)
}
```


```{r chapter-10-data-prep}
data("concrete", package = "AppliedPredictiveModeling")

mixture_means <- 
 mixtures %>% 
 clean_names() %>% 
 group_by(cement, blast_furnace_slag, fly_ash, water, superplasticizer, 
          coarse_aggregate, fine_aggregate, age) %>% 
 summarize(
  compressive_strength = mean(compressive_strength), 
  .groups = "drop"
 ) %>% 
 ungroup()
```


```{r chapter-10-data-splitting}
set.seed(1000)
concrete_split <- initial_split(mixture_means, strata = compressive_strength)
concrete_train <- training(concrete_split)
concrete_test  <- testing(concrete_split)

set.seed(1001)
concrete_folds <- vfold_cv(concrete_train, strata = compressive_strength, 
                           repeats = 5)
```


```{r chapter-10-recipes}
basic_recipe <- recipe(compressive_strength ~ ., data = concrete_train)

normalized_rec <- 
 basic_recipe %>% 
 step_normalize(all_predictors()) 

poly_recipe <- 
 normalized_rec %>% 
 step_interact(~ all_predictors():all_predictors()) %>% 
 step_poly(cement, blast_furnace_slag, fly_ash, water, superplasticizer, 
           coarse_aggregate, fine_aggregate, age)
```


```{r chapter-10-models}
linear_reg_spec <- 
 linear_reg(penalty = tune(), mixture = tune()) %>% 
 set_engine("glmnet")

nnet_spec <- 
 mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% 
 set_engine("nnet", MaxNWts = 2600) %>% 
 set_mode("regression")

mars_spec <- 
 mars(num_terms = tune(), prod_degree = tune(), prune_method = "none") %>% 
 set_engine("earth") %>% 
 set_mode("regression")

svm_r_spec <- 
 svm_rbf(cost = tune(), rbf_sigma = tune()) %>% 
 set_engine("kernlab") %>% 
 set_mode("regression")

svm_p_spec <- 
 svm_poly(cost = tune(), degree = tune()) %>% 
 set_engine("kernlab") %>% 
 set_mode("regression")

knn_spec <- 
 nearest_neighbor(neighbors = tune(), dist_power = tune(), weight_func = tune()) %>% 
 set_engine("kknn") %>% 
 set_mode("regression")

cart_spec <- 
 decision_tree(cost_complexity = tune(), min_n = tune()) %>% 
 set_engine("rpart") %>% 
 set_mode("regression")

bag_cart_spec <- 
 bag_tree() %>% 
 set_engine("rpart", times = 50L) %>% 
 set_mode("regression")

rf_spec <- 
 rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
 set_engine("ranger") %>% 
 set_mode("regression")

xgb_spec <- 
 boost_tree(tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(), 
            min_n = tune(), sample_size = tune(), trees = tune()) %>% 
 set_engine("xgboost") %>% 
 set_mode("regression")

cubist_spec <- 
 cubist_rules(committees = tune(), neighbors = tune()) %>% 
 set_engine("Cubist") 

rulefit_spec <- 
 rule_fit(tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(), 
          min_n = tune(), sample_size = tune(), trees = tune(), penalty = tune()) %>% 
 set_engine("xrf") %>% 
 set_mode("regression")
```


```{r chapter-10-make-workflows}
no_pre_proc <- 
 workflow_set(
  preproc = list(simple = compressive_strength ~ .), 
  models = list(MARS = mars_spec, CART = cart_spec, 'CART (bagged)' = bag_cart_spec,
                RF = rf_spec, boosting = xgb_spec, Cubist = cubist_spec),
  cross = TRUE
 )

normalized <- 
 workflow_set(
  preproc = list(normalized = normalized_rec), 
  models = list('SVM (radial)' = svm_r_spec, 'SVM (poly)' = svm_p_spec, 
                KNN = knn_spec, 'neural network' = nnet_spec),
  cross = TRUE
 )

with_features <- 
 workflow_set(
  preproc = list(full_quad = poly_recipe), 
  models = list('linear reg' = linear_reg_spec, KNN = knn_spec),
  cross = TRUE
 )
```

```{r chapter-10-workflow-fits, message = FALSE, cache = caching}
race_ctrl <- control_race(save_pred = TRUE, parallel_over = "everything", 
                          burn_in = 5)

all_workflows <- 
 bind_rows(no_pre_proc, normalized, with_features)

set.seed(1002)
workflow_fits <- 
 all_workflows %>% 
 filter(!(model %in% c("bag_tree", "svm_poly", "mars", "mlp"))) %>% 
 workflow_map(fn = "tune_race_anova", seed = 1003, 
              resamples = concrete_folds, grid = 50, control = race_ctrl)

resamp_ctrl <- control_race(save_pred = TRUE)
bag_fit <- 
 all_workflows %>% 
 filter(model == "bag_tree") %>% 
 workflow_map(fn = "fit_resamples", seed = 1003, resamples = concrete_folds, 
              control = resamp_ctrl)

svm_p_param <- 
 svm_p_spec %>% 
 parameters() %>% 
 update(degree = prod_degree())

set.seed(1002)
svm_p_fit <- 
 all_workflows %>% 
 filter(model == "svm_poly") %>% 
 workflow_map(fn = "tune_race_anova", seed = 1003, 
              resamples = concrete_folds, grid = 50, control = race_ctrl, 
              param_info = svm_p_param)

nnet_param <- 
 nnet_spec %>% 
 parameters() %>% 
 update(hidden_units = hidden_units(c(1, 27)))

set.seed(1002)
nnet_fit <- 
 all_workflows %>% 
 filter(model == "mlp") %>% 
 workflow_map(fn = "tune_race_anova", seed = 1003, 
              resamples = concrete_folds, grid = 50, control = race_ctrl, 
              param_info = nnet_param)

mars_param <- 
 mars_spec %>% 
 parameters() %>% 
 update(num_terms = num_terms(c(2, 20)))

set.seed(1002)
mars_fit <- 
 all_workflows %>% 
 filter(model == "mars") %>% 
 workflow_map(fn = "tune_race_anova", seed = 1003, 
              resamples = concrete_folds, grid = 50, control = race_ctrl, 
              param_info = mars_param)

workflow_fits <- 
 workflow_fits %>% 
 bind_rows(bag_fit, svm_p_fit, mars_fit, nnet_fit)
```

```{r chapter-10-workflow-eval}
autoplot(workflow_fits, rank_metric = "rmse", std_errs = qnorm(0.95))
rank_results(workflow_fits, rank_metric = "rmse") %>% 
 filter(.metric == "rmse")
```